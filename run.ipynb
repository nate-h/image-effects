{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4f0786a",
   "metadata": {},
   "source": [
    "# Image Effects\n",
    "\n",
    "My attempt at recreating trivial photoshop effects + some custom visualizations I find cool."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f62dedb",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Let's get these out of the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0e7ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import textwrap\n",
    "import math\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from src.utils import load_rgb, save_gray, adjust_exponential, plot\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b3eee5b",
   "metadata": {},
   "source": [
    "## Grayscale\n",
    "\n",
    "One might think grayscale is as easy as averaging the rgb channels but our eyes\n",
    "perceive things differently. Thus a better way to grayscale is to use non-linear\n",
    "weights when combining the rgb channels.\n",
    "\n",
    "More here: https://en.wikipedia.org/wiki/Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b21adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/lenna.png\")\n",
    "gray = np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "plot(1, 2, (\"Original\", rgb), (\"Gray\", gray))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c390359",
   "metadata": {},
   "source": [
    "## Hue shifting\n",
    "\n",
    "Load image as hsv then shift all colors using a simple offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a424d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load colorful image.\n",
    "rgb = load_rgb('img/food.jpg')\n",
    "hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "# Created shifted image.\n",
    "hue = hsv[..., 0]\n",
    "shift = 90\n",
    "shifted_hue = (hue + shift) % 180\n",
    "hsv[:, :, 0] = shifted_hue\n",
    "shifted_rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "# Plot comparison.\n",
    "plot(1, 2,\n",
    "    (\"Original\", rgb),\n",
    "    (\"Shifted Hue\", shifted_rgb),\n",
    "    figsize=(5, 5)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac7c4783",
   "metadata": {},
   "source": [
    "## Modeling macos dynamic backgrounds\n",
    "\n",
    "Use gamma correction to emulate macos dynamic backgrounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef4c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/beach.jpg\")\n",
    "gammas = [1.3, 1, 0.7, 0.4]\n",
    "\n",
    "divides = np.linspace(0, rgb.shape[1], 5).astype(int)\n",
    "for start, stop, gamma in zip(divides, divides[1:], gammas):\n",
    "    rgb[:,start:stop, :] = adjust_exponential(rgb[:,start:stop, :], gamma)\n",
    "\n",
    "plot(1, 1, (\"Modeling macos dynamic backgrounds\", rgb))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18c23543",
   "metadata": {},
   "source": [
    "## Shifting saturation\n",
    "\n",
    "Description: Same concept as previous demo but messing with saturation instead of gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd7232",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/beach.jpg\")\n",
    "hsv_exp = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "hsv_lin = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "saturations = [0.4, 0.7, 1, 1.3]\n",
    "divides = np.linspace(0, hsv_exp.shape[1], len(saturations) + 1).astype(int)\n",
    "\n",
    "for start, stop, saturation in zip(divides, divides[1:], saturations):\n",
    "    hsv_lin[:,start:stop, 1] = hsv_lin[:,start:stop, 1] * saturation\n",
    "    hsv_exp[:,start:stop, 1] = adjust_exponential(hsv_exp[:,start:stop, 1], saturation)\n",
    "\n",
    "# Display.\n",
    "plot(1, 3,\n",
    "    (\"rgb\", rgb),\n",
    "    (\"Linear\", cv2.cvtColor(hsv_lin, cv2.COLOR_HSV2RGB)),\n",
    "    (\"Exponential\", cv2.cvtColor(hsv_exp, cv2.COLOR_HSV2RGB)),\n",
    "    figsize=(10, 10)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f20dd37",
   "metadata": {},
   "source": [
    "## Color quantization + pixelation\n",
    "\n",
    "Use color quantization + pixelation to convert new mario photo into old 1980s version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f42b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image.\n",
    "rgb = load_rgb('img/mario.png')\n",
    "\n",
    "# Create pixelated image.\n",
    "orig_h, orig_w = rgb.shape[:2]\n",
    "pixel_w, pixel_h = (25, 38)\n",
    "down_sampled = cv2.resize(rgb, (pixel_w, pixel_h), interpolation=cv2.INTER_LINEAR)\n",
    "pixelated = cv2.resize(down_sampled, (orig_w, orig_h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# Quantize the pixelated image.\n",
    "n_colors = 7\n",
    "arr = pixelated.reshape((-1, 3))\n",
    "kmeans = KMeans(n_clusters=n_colors, n_init=\"auto\").fit(arr)\n",
    "labels = kmeans.labels_\n",
    "centers = kmeans.cluster_centers_\n",
    "quantized_pixelated = centers[labels].reshape(pixelated.shape).astype('uint8')\n",
    "\n",
    "# Show original, pixelated, quantized_pixelated.\n",
    "plot(1, 3,\n",
    "    (\"Original\", rgb),\n",
    "    (\"Pixelated\", pixelated),\n",
    "    (\"Quantized+Pixelation\", quantized_pixelated),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a5cb3",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8e951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/high-five.png\")\n",
    "reflected = cv2.flip(rgb, 1)\n",
    "joined = np.concatenate((rgb, reflected), axis=1)\n",
    "\n",
    "plot(1,1,\n",
    "    (\"Original + Reflected\", joined),\n",
    "    figsize=(3, 3)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83997570",
   "metadata": {},
   "source": [
    "## Median vs Gaussian blurs on noise reduction\n",
    "\n",
    "Both median and gaussian blur operations smooth out images but have different\n",
    "effects. Median blurring works by looking at every cell and taking the median of\n",
    "it and all neighboring cells. Gaussian blurring works by looking at every cell and\n",
    "averaging it with its neighboring cells.\n",
    "\n",
    "One benefit of median blurring is its good at getting rid of noise instead of\n",
    "averaging it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee51bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/wink.png\")\n",
    "noise = np.random.choice([0, 255], size=rgb.shape, p=[0.9, 0.1])\n",
    "noisy_rgb = (noise + rgb).astype('uint8')\n",
    "\n",
    "plot(2,2,\n",
    "    (\"Original\", rgb),\n",
    "    (\"With noise\", noisy_rgb),\n",
    "    (\"Median\", cv2.medianBlur(noisy_rgb, 5)),\n",
    "    (\"Gaussian\", cv2.GaussianBlur(noisy_rgb, (5,5), 0))\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6180887",
   "metadata": {},
   "source": [
    "## Erode and Dilate to fill in holes\n",
    "\n",
    "This demo will load an image of a dice, find the dice, then fill in the holes\n",
    "by enlarging and shrinking the mask of the dice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36696eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dice and convert to hsv.\n",
    "rgb = load_rgb(\"img/dice.png\")\n",
    "hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "# Select all the red to find the dice.\n",
    "lower = np.array([160, 0, 0], dtype=\"uint8\")\n",
    "upper = np.array([185, 255, 255], dtype=\"uint8\")\n",
    "mask = cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "# Fill in the holes by enlarging then shrinking the mask.\n",
    "kernel = np.ones((20, 20), np.uint8)\n",
    "dilated = cv2.dilate(mask, kernel, iterations=1)\n",
    "eroded = cv2.erode(dilated, kernel, iterations=1)\n",
    "\n",
    "# Display.\n",
    "plot(2, 2,\n",
    "    (\"Original\", rgb),\n",
    "    (\"Mask\", mask),\n",
    "    (\"Dilated\", dilated),\n",
    "    (\"Eroded\", eroded),\n",
    "    figsize=(3,3)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4712844",
   "metadata": {},
   "source": [
    "## Rotate a caret to create star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf7e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgra = cv2.imread(\"img/star_part.png\", flags=cv2.IMREAD_UNCHANGED)\n",
    "rgba = cv2.cvtColor(bgra, cv2.COLOR_BGR2RGBA)\n",
    "\n",
    "image_center = tuple(np.array(rgba.shape[1::-1]) / 2)\n",
    "\n",
    "star = rgba.copy()\n",
    "for i in range(1, 5):\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, 72*i, 1.0)\n",
    "    rotated = cv2.warpAffine(rgba, rot_mat, rgba.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    star += rotated\n",
    "\n",
    "plot(1, 2,\n",
    "    (\"Original\", rgba),\n",
    "    (\"5 rotations merged\", star),\n",
    "    figsize=(5,5)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b085683b",
   "metadata": {},
   "source": [
    "## Shifting portions of an image around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b85c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/pineapple.jpg\")\n",
    "shifted = np.zeros(rgb.shape, dtype=np.uint8)\n",
    "\n",
    "shift_scalar = 40\n",
    "height, width = rgb.shape[:-1]\n",
    "for i in range(height):\n",
    "    delta_x = int(shift_scalar * math.sin(math.radians(2*i)))\n",
    "    insert_x = max(0, delta_x)\n",
    "    insert_x2 = min(width, width + delta_x)\n",
    "    extract_x1 = max(0, -delta_x)\n",
    "    extract_x2 = min(width, width - delta_x)\n",
    "    shifted[i, insert_x:insert_x2] = rgb[i, extract_x1:extract_x2]\n",
    "\n",
    "plot(1, 2,\n",
    "    (\"Original\", rgb),\n",
    "    (\"Shifted\", shifted),\n",
    "    figsize=(4,4)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65a54256",
   "metadata": {},
   "source": [
    "## Noise gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7423c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/pineapple.jpg\")\n",
    "noise_gradient = np.zeros(rgb.shape, dtype=np.uint8)\n",
    "\n",
    "noise_scalar = 0.5\n",
    "height, width = rgb.shape[:-1]\n",
    "for i in range(height):\n",
    "    noise = np.random.normal(0, i * noise_scalar, (width, 3))\n",
    "    noise_gradient[i] = (rgb[i] + noise).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "plot(1, 2,\n",
    "    (\"Original\", rgb),\n",
    "    (\"Noise Gradient\", noise_gradient),\n",
    "    figsize=(4,4)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96a513f2",
   "metadata": {},
   "source": [
    "## Bloom effect\n",
    "\n",
    "Add a halo in an image and make it glow\n",
    "\n",
    "- Add halo in image\n",
    "- Blur mask of halo\n",
    "- Blend halo back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8553b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/person.png\")\n",
    "\n",
    "# Create halo.\n",
    "halo = np.zeros(shape=rgb.shape, dtype=np.uint8)\n",
    "center = (halo.shape[0] // 2, 9)\n",
    "halo_size = (40, 7)\n",
    "angle = 0\n",
    "start_angle = 0\n",
    "end_angle = 360\n",
    "thickness = 2\n",
    "color = (255, 223, 50)\n",
    "halo = cv2.ellipse(halo, center, halo_size, angle, start_angle, end_angle, color, thickness)\n",
    "halo = cv2.GaussianBlur(halo, (5, 5), sigmaX=3)\n",
    "\n",
    "# Blend the layers together.\n",
    "gain = 2\n",
    "overlaid_halo = cv2.addWeighted(rgb, 1, halo, gain, 0)\n",
    "\n",
    "# Display.\n",
    "plot(1, 3,\n",
    "    (\"Original\", rgb),\n",
    "    (\"Halo\", halo),\n",
    "    (\"Overlaid\", overlaid_halo),\n",
    "    figsize=(4,4)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b728c989",
   "metadata": {},
   "source": [
    "## Additive color mixing\n",
    "\n",
    "Tvs on a per pixel basis are actually made of three separate sub-pixels.\n",
    "The sub-pixels comprising of red, green, blue.\n",
    "I'm curious what recreating this effect looks like if I make an image pixel\n",
    "the subpixel and consider every three rows a pixel.\n",
    "\n",
    "I explore 2 different methods here:\n",
    "\n",
    "1. Make every row either red, green or blue depending on row mod 3x\n",
    "2. Resize by a factor of 3 then merge\n",
    "\n",
    "The result is lame lol. I'm essentially just throwing away 2/3 of the data but\n",
    "it was fun to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa81b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/parrot.jpg\")\n",
    "r, g, b = cv2.split(rgb)\n",
    "\n",
    "# Method 1: zeroing out channels.\n",
    "r[0::3] = 0\n",
    "r[1::3] = 0\n",
    "g[1::3] = 0\n",
    "g[2::3] = 0\n",
    "b[2::3] = 0\n",
    "b[0::3] = 0\n",
    "method_1 = cv2.merge((r, g, b))\n",
    "\n",
    "# Method 2: downsample then upsample selectively.\n",
    "h, w = rgb.shape[:-1]\n",
    "down_sampled_rgb = cv2.resize(rgb, (w, h//3))\n",
    "down_sampled_r, down_sampled_g, down_sampled_b = cv2.split(down_sampled_rgb)\n",
    "method_2 = np.zeros(rgb.shape, dtype=rgb.dtype)\n",
    "method_2[0::3, :, 0] = down_sampled_r\n",
    "method_2[1::3, :, 1] = down_sampled_g\n",
    "method_2[2::3, :, 2] = down_sampled_b\n",
    "\n",
    "# Display.\n",
    "plot(1, 3,\n",
    "    (\"Original\", rgb),\n",
    "    (\"Method 1\", method_1),\n",
    "    (\"Method 2\", method_2),\n",
    "    figsize=(5, 5)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e950b826",
   "metadata": {},
   "source": [
    "## Cut out text overlay effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe180ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rgb = load_rgb(\"img/fashion_portrait.jpg\")\n",
    "height, width = rgb.shape[:-1]\n",
    "\n",
    "def create_text_mask(fontFace, fontScale):\n",
    "    lorem_ipsum = (\"Lorem ipsum dolor sit amet, consectetur adipiscing elit, \"\n",
    "        \"sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. \"\n",
    "        \"Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris \"\n",
    "        \"nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in \"\n",
    "        \"reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla \"\n",
    "        \"pariatur. Excepteur sint occaecat cupidatat non proident, sunt in \"\n",
    "        \"culpa qui officia deserunt mollit anim id est laborum.\"\n",
    "    )\n",
    "    wrapped_text = textwrap.wrap(lorem_ipsum, width=35)\n",
    "    text_mask = np.zeros(rgb.shape, np.uint8)\n",
    "    for i, line in enumerate(wrapped_text, start=1):\n",
    "        cv2.putText(\n",
    "            text_mask,\n",
    "            text=line,\n",
    "            org=(0, i*40),\n",
    "            fontFace=fontFace,\n",
    "            fontScale=fontScale,\n",
    "            color=(255,255,255),\n",
    "            thickness=3\n",
    "        )\n",
    "    return text_mask\n",
    "\n",
    "# Create text masks.\n",
    "text_mask_1 = create_text_mask(7, 3)\n",
    "text_mask_2 = create_text_mask(0, 1)\n",
    "\n",
    "# Rotate second text mask.\n",
    "image_center = tuple(np.array((height, width)) / 2)\n",
    "rot_mat = cv2.getRotationMatrix2D(image_center, 90, 1.0)\n",
    "text_mask_2 = cv2.warpAffine(text_mask_2, rot_mat, (height, width), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "# Combine text masks then use that as a mask for the rgb image.\n",
    "text_mask = cv2.bitwise_or(text_mask_1, text_mask_2)\n",
    "combined = cv2.bitwise_and(rgb, text_mask)\n",
    "\n",
    "# Display.\n",
    "plot(1, 3,\n",
    "    (\"Original\", rgb),\n",
    "    (\"Text\", text_mask),\n",
    "    (\"Combined\", combined),\n",
    "    figsize=(7, 7)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ed0ec54",
   "metadata": {},
   "source": [
    "## Find tennis ball\n",
    "\n",
    "\n",
    "To find the tennis ball:\n",
    "\n",
    "- Look for it's approximate colors\n",
    "- Try to filter out unwanted colors\n",
    "- Find the contour around the blobs found in the mask\n",
    "- Find the minimum circle around the biggest blob and consider it the ball\n",
    "\n",
    "Note: the values for the threshold we're very precisely tuned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202136f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/tennis_ball.jpg\")\n",
    "smoothed_rgb = cv2.GaussianBlur(rgb, (11, 11), 0)\n",
    "hsv = cv2.cvtColor(smoothed_rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "# Find pixels likely belonging to tennis ball.\n",
    "lower = np.array((34, 152, 132), dtype=\"uint8\")\n",
    "upper = np.array((44, 255, 255), dtype=\"uint8\")\n",
    "threshold = cv2.inRange(hsv, lower, upper)\n",
    "eroded = cv2.erode(threshold, np.ones((5, 5), np.uint8), iterations=3)\n",
    "dilated = cv2.dilate(eroded, np.ones((5, 5), np.uint8), iterations=4)\n",
    "\n",
    "# Find tennis ball from probable tennis ball pixels.\n",
    "contours, _ = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "rgb_copy = rgb.copy()\n",
    "cv2.drawContours(rgb_copy, contours, -1, 255, 3)\n",
    "(x,y),radius = cv2.minEnclosingCircle(contours[0])\n",
    "center = (int(x),int(y))\n",
    "radius = int(radius)\n",
    "cv2.circle(rgb_copy, center,radius,(0,255,0),2)\n",
    "\n",
    "# Display.\n",
    "plot(1,6,\n",
    "    (\"Original\", rgb),\n",
    "    (\"Smoothed\", smoothed_rgb),\n",
    "    (\"Threshold\", threshold),\n",
    "    (\"Eroded\", eroded),\n",
    "    (\"Dilated\", dilated),\n",
    "    (\"Found\", rgb_copy),\n",
    "    figsize=(7,7)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "799dd2b1",
   "metadata": {},
   "source": [
    "## Finding the horizon using a canny edge detector\n",
    "\n",
    "For this demo, I wanted to explore using a canny edge detector to separate the\n",
    "ground from the sky. Took a bit of work to find the right settings for the gaussian\n",
    "filter and canny hysteresis threshold.\n",
    "\n",
    "The gaussian filter is used to weed out weak edges in order to isolate the horizon.\n",
    "\n",
    "The [hysteresis threshold](https://theailearner.com/tag/hysteresis-thresholding/)\n",
    "controls how the edge detector connects weak edges to strong edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0df573",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/sunset.jpg\")\n",
    "gaussian = cv2.GaussianBlur(rgb, (21, 21), 0)\n",
    "\n",
    "# Explore canny edge detectors w/ and w/o smoothing.\n",
    "t1 = 100\n",
    "t2 = 240\n",
    "canny_rgb = cv2.Canny(image=rgb, threshold1=t1, threshold2=t2)\n",
    "canny_gaussian = cv2.Canny(image=gaussian, threshold1=t1, threshold2=t2)\n",
    "\n",
    "# Create new image.\n",
    "separated = np.zeros(rgb.shape, dtype=np.uint8)\n",
    "top_color = (255,0,0)\n",
    "middle_color = (255,255,255)\n",
    "bottom_color = (0,0,255)\n",
    "thickness = 30\n",
    "for col_index, col in enumerate(canny_gaussian.T):\n",
    "    sep = int(np.where(col == 255)[0].mean())\n",
    "    separated[:sep-thickness,col_index,:] = top_color\n",
    "    separated[sep-thickness:sep+thickness,col_index,:] = middle_color\n",
    "    separated[sep+thickness + 1:,col_index,:] = bottom_color\n",
    "\n",
    "# Display.\n",
    "plot(1,5,\n",
    "    (\"RGB\", rgb),\n",
    "    (\"Gaussian\", gaussian),\n",
    "    (\"Canny RGB\", canny_rgb),\n",
    "    (\"Canny Gaussian\", canny_gaussian),\n",
    "    (\"Horizon\", separated),\n",
    "    figsize=(7,7)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb187332",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-effects",
   "language": "python",
   "name": "image-effects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
