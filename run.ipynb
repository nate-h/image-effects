{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4f0786a",
   "metadata": {},
   "source": [
    "# Image Effects\n",
    "\n",
    "My attempt at recreating trivial photoshop effects + some custom visualizations I find cool."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f62dedb",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Let's get these out of the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0e7ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import math\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from src.utils import load_rgb, save_gray, adjust_exponential, plot\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b3eee5b",
   "metadata": {},
   "source": [
    "## Grayscale\n",
    "\n",
    "One might think grayscale is as easy as averaging the rgb channels but our eyes\n",
    "perceive things differently. Thus a better way to grayscale is to use non-linear\n",
    "weights when combining the rgb channels.\n",
    "\n",
    "More here: https://en.wikipedia.org/wiki/Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b21adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/lenna.png\")\n",
    "gray = np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "plot(1, 2, (\"Original\", rgb), (\"Gray\", gray))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c390359",
   "metadata": {},
   "source": [
    "## Hue shifting\n",
    "\n",
    "Load image as hsv then shift all colors using a simple offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a424d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load colorful image.\n",
    "rgb = load_rgb('img/food.jpg')\n",
    "hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "# Created shifted image.\n",
    "hue = hsv[..., 0]\n",
    "shift = 90\n",
    "shifted_hue = (hue + shift) % 180\n",
    "hsv[:, :, 0] = shifted_hue\n",
    "shifted_rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "# Plot comparison.\n",
    "plot(1, 2,\n",
    "    (\"Original\", rgb),\n",
    "    (\"Shifted Hue\", shifted_rgb),\n",
    "    figsize=(5, 5)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac7c4783",
   "metadata": {},
   "source": [
    "## Modeling macos dynamic backgrounds\n",
    "\n",
    "Use gamma correction to emulate macos dynamic backgrounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef4c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/beach.jpg\")\n",
    "gammas = [1.3, 1, 0.7, 0.4]\n",
    "\n",
    "divides = np.linspace(0, rgb.shape[1], 5).astype(int)\n",
    "for start, stop, gamma in zip(divides, divides[1:], gammas):\n",
    "    rgb[:,start:stop, :] = adjust_exponential(rgb[:,start:stop, :], gamma)\n",
    "\n",
    "plot(1, 1, (\"Modeling macos dynamic backgrounds\", rgb))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18c23543",
   "metadata": {},
   "source": [
    "## Shifting saturation\n",
    "\n",
    "Description: Same concept as previous demo but messing with saturation instead of gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd7232",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/beach.jpg\")\n",
    "hsv_exp = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "hsv_lin = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "saturations = [0.4, 0.7, 1, 1.3]\n",
    "divides = np.linspace(0, hsv_exp.shape[1], len(saturations) + 1).astype(int)\n",
    "\n",
    "for start, stop, saturation in zip(divides, divides[1:], saturations):\n",
    "    hsv_lin[:,start:stop, 1] = hsv_lin[:,start:stop, 1] * saturation\n",
    "    hsv_exp[:,start:stop, 1] = adjust_exponential(hsv_exp[:,start:stop, 1], saturation)\n",
    "\n",
    "# Display.\n",
    "plot(1, 3,\n",
    "    (\"rgb\", rgb),\n",
    "    (\"Linear\", cv2.cvtColor(hsv_lin, cv2.COLOR_HSV2RGB)),\n",
    "    (\"Exponential\", cv2.cvtColor(hsv_exp, cv2.COLOR_HSV2RGB)),\n",
    "    figsize=(10, 10)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f20dd37",
   "metadata": {},
   "source": [
    "## Color quantization + pixelation\n",
    "\n",
    "Use color quantization + pixelation to convert new mario photo into old 1980s version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f42b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image.\n",
    "rgb = load_rgb('img/mario.png')\n",
    "\n",
    "# Create pixelated image.\n",
    "orig_h, orig_w = rgb.shape[:2]\n",
    "pixel_w, pixel_h = (25, 38)\n",
    "down_sampled = cv2.resize(rgb, (pixel_w, pixel_h), interpolation=cv2.INTER_LINEAR)\n",
    "pixelated = cv2.resize(down_sampled, (orig_w, orig_h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# Quantize the pixelated image.\n",
    "n_colors = 7\n",
    "arr = pixelated.reshape((-1, 3))\n",
    "kmeans = KMeans(n_clusters=n_colors, n_init=\"auto\").fit(arr)\n",
    "labels = kmeans.labels_\n",
    "centers = kmeans.cluster_centers_\n",
    "quantized_pixelated = centers[labels].reshape(pixelated.shape).astype('uint8')\n",
    "\n",
    "# Show original, pixelated, quantized_pixelated.\n",
    "plot(1, 3,\n",
    "    (\"Original\", rgb),\n",
    "    (\"Pixelated\", pixelated),\n",
    "    (\"Quantized+Pixelation\", quantized_pixelated),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a5cb3",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8e951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/high-five.png\")\n",
    "reflected = cv2.flip(rgb, 1)\n",
    "joined = np.concatenate((rgb, reflected), axis=1)\n",
    "\n",
    "plot(1,1,\n",
    "    (\"Original + Reflected\", joined),\n",
    "    figsize=(3, 3)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83997570",
   "metadata": {},
   "source": [
    "## Median vs Gaussian blurs on noise reduction\n",
    "\n",
    "Both median and gaussian blur operations smooth out images but have different\n",
    "effects. Median blurring works by looking at every cell and taking the median of\n",
    "it and all neighboring cells. Gaussian blurring works by looking at every cell and\n",
    "averaging it with its neighboring cells.\n",
    "\n",
    "One benefit of median blurring is its good at getting rid of noise instead of\n",
    "averaging it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee51bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/wink.png\")\n",
    "noise = np.random.choice([0, 255], size=rgb.shape, p=[0.9, 0.1])\n",
    "noisy_rgb = (noise + rgb).astype('uint8')\n",
    "\n",
    "plot(2,2,\n",
    "    (\"Original\", rgb),\n",
    "    (\"With noise\", noisy_rgb),\n",
    "    (\"Median\", cv2.medianBlur(noisy_rgb, 5)),\n",
    "    (\"Gaussian\", cv2.GaussianBlur(noisy_rgb, (5,5), 0))\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6180887",
   "metadata": {},
   "source": [
    "## Erode and Dilate to fill in holes\n",
    "\n",
    "This demo will load an image of a dice, find the dice, then fill in the holes\n",
    "by enlarging and shrinking the mask of the dice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36696eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dice and convert to hsv.\n",
    "rgb = load_rgb(\"img/dice.png\")\n",
    "hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "# Select all the red to find the dice.\n",
    "lower = np.array([160, 0, 0], dtype=\"uint8\")\n",
    "upper = np.array([185, 255, 255], dtype=\"uint8\")\n",
    "mask = cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "# Fill in the holes by enlarging then shrinking the mask.\n",
    "kernel = np.ones((20, 20), np.uint8)\n",
    "dilated = cv2.dilate(mask, kernel, iterations=1)\n",
    "eroded = cv2.erode(dilated, kernel, iterations=1)\n",
    "\n",
    "# Display.\n",
    "plot(2, 2,\n",
    "    (\"Original\", rgb),\n",
    "    (\"Mask\", mask),\n",
    "    (\"Dilated\", dilated),\n",
    "    (\"Eroded\", eroded),\n",
    "    figsize=(3,3)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4712844",
   "metadata": {},
   "source": [
    "## Rotate a caret to create star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf7e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgra = cv2.imread(\"img/star_part.png\", flags=cv2.IMREAD_UNCHANGED)\n",
    "rgba = cv2.cvtColor(bgra, cv2.COLOR_BGR2RGBA)\n",
    "\n",
    "image_center = tuple(np.array(rgba.shape[1::-1]) / 2)\n",
    "\n",
    "star = rgba.copy()\n",
    "for i in range(1, 5):\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, 72*i, 1.0)\n",
    "    rotated = cv2.warpAffine(rgba, rot_mat, rgba.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    star += rotated\n",
    "\n",
    "plot(1, 2,\n",
    "    (\"Original\", rgba),\n",
    "    (\"5 rotations merged\", star),\n",
    "    figsize=(5,5)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b085683b",
   "metadata": {},
   "source": [
    "## Shifting portions of an image around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b85c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/pineapple.jpg\")\n",
    "shifted = np.zeros(rgb.shape, dtype=np.uint8)\n",
    "\n",
    "shift_scalar = 40\n",
    "height, width = rgb.shape[:-1]\n",
    "for i in range(height):\n",
    "    delta_x = int(shift_scalar * math.sin(math.radians(2*i)))\n",
    "    insert_x = max(0, delta_x)\n",
    "    insert_x2 = min(width, width + delta_x)\n",
    "    extract_x1 = max(0, -delta_x)\n",
    "    extract_x2 = min(width, width - delta_x)\n",
    "    shifted[i, insert_x:insert_x2] = rgb[i, extract_x1:extract_x2]\n",
    "\n",
    "plot(1, 2,\n",
    "    (\"Original\", rgb),\n",
    "    (\"Shifted\", shifted),\n",
    "    figsize=(4,4)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65a54256",
   "metadata": {},
   "source": [
    "## Noise gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7423c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/pineapple.jpg\")\n",
    "noise_gradient = np.zeros(rgb.shape, dtype=np.uint8)\n",
    "\n",
    "noise_scalar = 0.5\n",
    "height, width = rgb.shape[:-1]\n",
    "for i in range(height):\n",
    "    noise = np.random.normal(0, i * noise_scalar, (width, 3))\n",
    "    modded = rgb[i] + noise\n",
    "    modded[modded > 255] = 255\n",
    "    modded[modded < 0] = 0\n",
    "    noise_gradient[i] = modded.astype(\"uint8\")\n",
    "\n",
    "plot(1, 2,\n",
    "    (\"Original\", rgb),\n",
    "    (\"Noise Gradient\", noise_gradient),\n",
    "    figsize=(4,4)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96a513f2",
   "metadata": {},
   "source": [
    "## Bloom effect\n",
    "\n",
    "Add a halo in an image and make it glow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8553b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = load_rgb(\"img/person.png\")\n",
    "\n",
    "# Create halo.\n",
    "halo = np.zeros(shape=rgb.shape, dtype=np.uint8)\n",
    "dim = halo.shape[0]\n",
    "center = (dim//2, 15)\n",
    "halo_size = (40, 10)\n",
    "angle = 0\n",
    "start_angle = 0\n",
    "end_angle = 360\n",
    "color = (255, 215, 0)\n",
    "thickness = 2\n",
    "halo = cv2.ellipse(halo, center, halo_size, angle, start_angle, end_angle, color, thickness)\n",
    "\n",
    "halo = cv2.GaussianBlur(halo, (5,5), 0)\n",
    "\n",
    "print((rgb + halo).shape)\n",
    "print(halo.dtype)\n",
    "print((rgb + halo).dtype)\n",
    "\n",
    "# Display.\n",
    "plot(1, 3,\n",
    "    (\"Original\", rgb),\n",
    "    (\"Halo\", halo),\n",
    "    (\"Overlaid\", rgb + halo),\n",
    "    figsize=(4,4)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d492b7d9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e950b826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e8f1ebb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-effects",
   "language": "python",
   "name": "image-effects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
